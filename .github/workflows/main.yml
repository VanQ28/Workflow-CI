name: CI - Amazon Sales Retrain + Docker

on:
  push:
    branches: ["main"]
  workflow_dispatch:

permissions:
  contents: write

jobs:
  retrain:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install mlflow==2.19.0 dagshub pandas scikit-learn matplotlib

      - name: Debugging - Cek File
        run: |
          ls -R # Melihat semua folder agar kita tahu lokasi Modelling.py yang tepat

      - name: Run Training Script
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          # PINDAH KE FOLDER MLProject
          cd MLProject
          
          # JALANKAN PYTHON LANGSUNG (PASTIKAN M BESAR/KECIL SESUAI NAMA FILE)
          # Jika nama file Anda modelling.py (kecil semua), ganti Modelling.py di bawah:
          python Modelling.py \
            --train_path Amazon_Preprocessing/amazon_train.csv \
            --test_path Amazon_Preprocessing/amazon_test.csv \
            --experiment_name Amazon_Sales_Project \
            --run_name ci_rf_training

      - name: Collect Artifacts
        if: success()
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          python - << 'PY'
          import os, shutil, mlflow
          repo = "VanQ28/Workflow_CI"
          mlflow.set_tracking_uri(f"https://dagshub.com/{repo}.mlflow")
          
          run = mlflow.search_runs(experiment_names=["Amazon_Sales_Project"], order_by=["start_time DESC"], max_results=1).iloc[0]
          run_id = run.run_id
          print(f"Mengambil model dari Run ID: {run_id}")
          
          out = f"ci_outputs/{run_id}"
          os.makedirs(out, exist_ok=True)
          
          # Ambil folder model
          path = mlflow.artifacts.download_artifacts(run_id=run_id, artifact_path="model")
          shutil.copytree(path, f"{out}/model", dirs_exist_ok=True)
          
          with open(f"{out}/run_id.txt", "w") as f: f.write(run_id)
          PY

      - name: Commit & Push
        if: success()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add ci_outputs/ || true
          git commit -m "CI: Save model artifacts" || echo "No changes"
          git push

  docker:
    needs: retrain
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Login Docker Hub
        run: echo "${{ secrets.DOCKERHUB_TOKEN }}" | docker login -u "${{ secrets.DOCKERHUB_USERNAME }}" --password-stdin
      - name: Build & Push Docker
        run: |
          pip install mlflow==2.19.0 scikit-learn pandas
          RUN_ID=$(ls -1 ci_outputs/ | head -n 1)
          IMAGE="${{ secrets.DOCKERHUB_USERNAME }}/amazon-sales-ci:latest"
          mlflow models build-docker -m "ci_outputs/${RUN_ID}/model" -n "$IMAGE"
          docker push "$IMAGE"
